---
title: 머신러닝 프로젝트 (Hands-On Machine Learning Part1)
date: 2021-09-11 02:26 +0900
categories: [machine learning]
tags: [machine learning]
mermaid: true
math: true
---

## 머신러닝 프로젝트의 형태

- 데이터 분석
- 모델 선택
- 훈련 데이터로 모델을 훈련시킨다 (비용 함수를 최소화 하는 모델 파라미터를 찾는다)
- 새로운 데이터에 모델을 적용해 예측(추론)하고 일반화가 잘 되길 기다린다

## 사이킷런을 이용한 선형 모델의 훈련과 실행

```python
import numpy as np
import pandas as pd
import sklearn.linear_model

from pkg import *

oecd_bli = pd.read_csv('../handson-ml2/datasets/lifesat/oecd_bli_2015.csv',
                       thousands=',')
gdp_per_capita = pd.read_csv('../handson-ml2/datasets/lifesat/gdp_per_capita.csv',
                             thousands=',', delimiter='\t', encoding='latin1',
                             na_values='n/a')

# 데이터 준비
country_status = prepare_country_stats(oecd_bli, gdp_per_capita)
X = np.c_[country_status["GDP per capita"]]
y = np.c_[country_status["Life satisfaction"]]

# 데이터 시각화
country_status.plot(kind='scatter', x='GDP per capita', y='Life satisfaction')
plt.show()

# 선형 모델 선택
model = sklearn.linear_model.LinearRegression()

# 모델 훈련
model.fit(X, y)

# 키프로스에 대한 예측
X_new = [[22587]]
print(model.predict(X_new))
```

- `LinearRegression()`을 사용하여 모델을 훈련시킨 후 키프로스에 대한 예측을 했다
- 사례기반의 학습 알고리즘을 사용하면 1인당 GDP가 키프로스와 가까운 슬로베니아를 찾는다
- 더 나아가 그 다음으로 가까운 두 나라를 고려해 세 나라의 평균으로 GDP를 예측할 수 있으며 이러한 방법을 "k-최근접 이웃" 회귀라고 한다
- `np.c_`는 두 개의 1차원 배열을 column으로 세로로 붙여서 2차원 배열을 만들어 준다

```python
a = np.array([1, 2, 3, 4])
b = np.array([6, 7, 8, 9])

print(np.c_[a, b])
----------------------------
[[1 6]
 [2 7]
 [3 8]
 [4 9]]
```

## 머신러닝의 주요 도전 과제

### 나쁜 데이터의 종류는 다음과 같다

#### 충분하지 않은 양의 훈련 데이터

#### 대표성 없는 훈련 데이터

- 일반화가 잘되려면 우리가 일반화하기 원하는 새로운 사례를 훈련 데이터가 잘 대표하는 것이 중요하다
- 샘플이 작으면 sampling noise가 생기고 매우 큰 샘플도 표본 추출 방법이 잘못되면 대표성을 띠지 못할 수 있다 이것을 sampling bias(샘플링 편형)라고 한다

#### 낮은 품질의 데이터

- 훈련 데이터가 에러, 이상치, 잡음으로 가득하면 머신러닝 시스템이 내재된 패턴을 찾기 어려워 작동하지 않을것이다

###### 훈련 데이터 정제가 필요한 경우

- 일부 샘플이 이상치라는게 명확하다면 간단히 그것들을 무시하거나 수동으로 잘못된 것을 고치는 것이 좋다
- 일부 샘플에 특성 몇개가 빠져있다면 이 특성 모두 무시할지, 이 샘플을 무시할지, 빠진 값을 채울지 또는 이 특성을 넣은 모델과 제외한 모델을 따로 훈련시킬 것인지 결정해야 한다

#### 관련 없는 특성

- 성공적인 머신러닝 프로젝트의 핵심 요소는 훈련에 사용할 좋은 특성들을 찾는 것이다
- **특성 선택:** 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택한다
- **특성 추출:** 특성을 결합하여 더 유용한 특성을 만든다. 앞서 본 것처럼 차원 축소 알고리즘이 도움이 될 수 있다
- 새로운 데이터를 수집해 새로운 특성을 만든다

#### 훈련 데이터 과대적합

- 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어지게 되고 과대적합이 된다

###### 과대적합을 피하기 위한 방법

- 파라미터 수가 적은 모델을 선택하거나 훈련 데이터에 있는 특성 수를 줄이거나 모델에 제약을 가하여 단순화시킨다
- 훈련 데이터를 더 많이 모은다
- 훈련 데이터의 잡음을 줄인다 (오류 데이터 수정과 이상치 제거)

#### 훈련 데이터 과소적합

- 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 일어난다

###### 과소적합을 피하기 위한 방법

- 모델 파라미터가 더 많은 강력한 모델을 선택한다
- 학습 알고리즘에 더 좋은 특성을 제공한다
- 모델의 제약을 줄인다 (규제 하이퍼파라미터를 감소시킨다)

## 테스트와 검증

- 새로운 샘플에 모델을 실제로 적용해보면 모델이 얼마나 잘 일반화가 되었는지 알 수 있다
- 훈련 세트와 테스트 세트 두 개로 나누는 것이 좋다
- 새로운 샘플에 대한 오류 비율을 `일반화 오차`또는 `외부 샘플 오차`라고 한다
- 테스트 세트에서 모델을 평가함으로써 오차에 대한 추정값을 얻는다

### 하이퍼 파라미터 튜닝과 모델 선택

- 일반화 오차를 테스트 세트에서 여러번 측정해서 테스트 세트에 최적화된 모델이 만들어지면 다른 새로운 데이터에는 잘 작동하지 않을 수 있다 해결방법은 `홀드아웃 검증`과 `교차 검증`이 있다

#### 홀드 아웃 검증

- 훈련 세트의 일부를 떼어내어 여러 후보 모델을 평가하고 가장 좋은 하나를 선택한다
- 새로운 홀드 아웃 세트를 `검증 세트`라고 한다
- 줄어든 훈련 세트에서 다양한 하이퍼파라미터 값을 가진 여러 모델을 훈련하고 그 다음 검증 세트에서 가장 높은 성능을 내는 모델을 선택한다
- 홀드아웃 검증 과정이 끝나면 최선의 모델을 전체 훈련 세트에서 다시 훈련하여 최종 모델을 만든다
- 검증 세트가 너무 작으면 모델이 정확하게 평가되지 않고 검증 세트가 너무 크면 남은 훈련 세트가 너무 작아진다 이것을 해결하기 위해 `교차 검증`을 사용한다

#### 교차 검증

- 검증 세트마다 나머지 데이터에서 훈련한 모델을 해당 검증 세트에 평가한다
- 모든 모델의 평가를 평균하면 훨씬 정확한 성능을 측정할 수 있다
- 훈련 시간이 검증 세트의 개수에 비례해 늘어나는 단점이 있다
